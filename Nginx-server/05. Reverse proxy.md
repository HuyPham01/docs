# Reverse proxy

Đây là một trong những tính năng tuyệt vời của Nginx. Trong những cách đơn giản nhất, một reverse proxy là một server nằm giữa các ứng dụng nội bộ và các client bên ngoài, forwarding client requests tới server phù hợp. Nó nhận một yêu cầu từ client, chuyển nó tới một hoặc nhiều servers, và sau đó chuyển lại phản hồi của máy chủ tới client.

Proxy thường được sử dụng để phân phối tải giữa một số server, truyền tải liền mạch nội dung từ các trang web khác nhau hoặc chuyển yêu cầu đang xử lý đến các máy chủ ứng dụng qua các giao thức khác ngoài HTTP.

Một reverse proxy có thể giảm tải nhiều mối quan tâm về cơ sở hạ tầng của một ứng dụng web phân tán khối lượng lớn.

![image](https://github.com/HuyPham01/docs/assets/96679595/ded879ba-5ded-48b5-8ff1-e7d2e56d6ccc)


Reverse proxy cung cấp cho bạn một số tính năng nâng cao như:

* load balancing, failover, và transparent maintenance của các backend server
* Tăng cường an ninh (ví dụ: SSL termination, ẩn upstream còniguration)
* Tăng hiệu năng (ví dụ: caching, load blancing)
* Đơn giản hóa access control responsibilities (single point of access and maintenance)
* Tập trung vào logging và auditing (single point of maintenance)
* add/remove/modify HTTP headers

Với Reverse proxy, hai điều cần quan tâm nhất là cách thức để các requests được chuyển tiếp tới backend và loại headers được chuyển tiếp tới backend.

Một reverse proxy cung cấp một vài điều để làm server của bạn bảo mật hơn:

* là nơi để đặt monitor và log tất cả mọi request đi tới webserver
* là nơi để lọc tách từ web server của bạn nếu bạn biết rằng hệ thống của bạn rất dễ có lỗ hổng. Dựa vào proxy bạn có thể lọc ở tầng ứng dụng
* là nơi để triển khai ACLs và các rules nếu bạn có không thể làm được trên web server của bạn.
* một network stack riêng không dế bị tấn công giống cách với web server của bạn. 
* một reverse proxy không filtering sẽ không tự động bảo vệ bạn chống lại mọi thứ, nhưng nếu hệ thống của bạn cần bảo vệ thì việc thêm reverse proxy ngược có thể xứng đáng với chi phí thực hiện và chi phí hỗ trợ.

## Passing requests

Khi Nginx nhận được một request cần proxy, nó sẽ gửi gửi request đó tới một server được proxied, lấy phản hồi và gửi lại cho client.

Nó có thể gửi requests proxy tới:

* một HTTP servers (ví dụ: Nginx, Apache,...) với `proxy_pass` directive: 

```nginx
upstream bk_front {

  server 192.168.252.20:8080  weight=5;
  server 192.168.252.21:8080

}

server {

  location / {

    proxy_pass    http://bk_front;

  }

  location /api {

    proxy_pass    http://192.168.21.20:8080;

  }

  location /info {

    proxy_pass    http://localhost:3000;

  }

  location /ra-client {

    proxy_pass    http://10.0.11.12:8080/guacamole/;

  }

  location /foo/bar/ {

    proxy_pass    http://www.example.com/url/;

  }

  ...

}
```

* Một server không phải HTTP server (non-HTTP server, ví dụ: PHP, Node.js, Python, Java,...) với `proxy_pass` directive (như một fallback) hoặc directive được thiết kế đặc biệt:

    * `fastcgi_pass` which passes a request to a FastCGI server

       ```nginx
        server {

          ...

          location ~ ^/.+\.php(/|$) {

            fastcgi_pass    127.0.0.1:9000;
            include         /etc/nginx/fcgi_params;

          }

          ...

        }
        ```

    * `uwsgi_pass` which passes a request to a uWSGI server:
        
       ```nginx
        server {

          location / {

            root            html;
            uwsgi_pass      django_cluster;
            uwsgi_param     UWSGI_SCRIPT testapp;
            include         /etc/nginx/uwsgi_params;

          }

          ...

        }
        ```
       
    * `scgi_pass` which passes a request to an SCGI server:

       ```nginx
        server {

          location / {

            scgi_pass       127.0.0.1:4000;
            include         /etc/nginx/scgi_params;

          }

          ...

        }
        ```

    * `memcached_pass` which passes a request to a Memcached server:

       ```nginx
        server {

          location / {

            set            $memcached_key "$uri?$args";
            memcached_pass memc_instance:4004;

            error_page     404 502 504 = @memc_fallback;

          }

          location @memc_fallback {

            proxy_pass     http://backend;

          }

          ...

        }
        ```

    * `redis_pass` which passes a request to a Redis server ([HTTP Redis](https://www.nginx.com/resources/wiki/modules/redis/)):

       ```nginx
        server {

          location / {

            set            $redis_key $uri;

            redis_pass     redis_instance:6379;
            default_type   text/html;
            error_page     404 = /fallback;

          }

          location @fallback {

            proxy_pass     http://backend;

          }

          ...

        }
        ```


## Trailing slashes

Ở đây ta có một ví dụ:

```sh
location /public/ {

  proxy_pass http://bck_testing_01;

}
``` 

Khi client truy cập vào `http://example.com/public`, Nginx sẽ tự động chuyển hướng client tới  `http://example.com/public/`

Thêm ví dụ nữa:

```sh
location /foo/bar/ {

  # proxy_pass  http://example.com/url/;
  proxy_pass    http://192.168.100.20/url/;

}
```

Nếu URI được chỉ định với địa chỉ IP, thì nó thay thế một phần của request URI match với location parameter. Ví dụ, ở đây request là `/foo/bar/page.html`, URI sẽ được chuyển thành `http://www.example.com/url/page.html`.

Nếu địa chỉ được chỉ định không có URI, hoặc không thể xác định phần URI để thay thế, toàn bộ request URI sẽ được passed (có thể đã được chỉnh sửa)

Ví dụ về trailing slash (theo sau là một dấu gạch chéo) trong location, nhưng không có trailing slash trong `proxy_pass`:

```nginx
location /foo/ {

  proxy_pass  http://127.0.0.1:8080/bar;

}
```

Nếu có một yêu cầu đi đến địa chỉ `http://yourserver.com/foo/path/id?param=1` Nginx sẽ proxy request tới `http://127.0.0.1/barpath/id?param=1`

Nếu `proxy_pass` được sử dụng mà không có URI (tức là không có đường dẫn sau phần `server:port`) Nginx sẽ đặt URI từ request exactly gốc với 2 dấu gạch chéo `//`

## Passing headers

Mặc định, Nginx sẽ xác định lại hai trường header trong proxied requests:

* `Host` header được viết lại các giá trị được định nghĩa bằng biến `$proxy_host`. Cái này sẽ là IP hoặc name và port của upstream, trực tieps như được định nghĩa bởi `proxy_pass` directive.

* `Connection` header được chuyển thành `close`. Header này thường sử dụng thông tin tín hiệu về các kết nối được thành lập giữa hai bên. Trong ví dụ này, Nginx thiết lập là `close` để chỉ ra cho upstream server rằng kết nối này sẽ được đóng sau khi request gốc được phản hồi. Upstream không nên mong đợi kết nối này là kết nối lâu dài.

Khi Nginx proxies một request, nó sẽ tự động có một vài điều chỉnh với request header mà nó nhận từ client:

* Nginx sẽ bỏ đi các header rỗng
* Mặc định thì Nginx sẽ xem xét tất cả các header chứa dấu gạch dưới là không khả dụng. Nó sẽ loại bỏ chúng từ proxied request. Nếu bạn muốn Nginx coi nó là valid, thì có thể set `underscores_in_headers` directive là `on`, nếu không tất cả các request này sẽ không thể đến được backend server.

Nó quan trong hơn là nó phải pass nhiều hơn là chỉ với các URI nếu bạn muốn upstream server xử lý các yêu cầu đúng cách. request đến từ Nginx thay cho các client sẽ khác với các request trực tiếp từ client.

Nginx sử dụng `proxy_set_header` directive để thiết lập headers gửi tới backend servers.

Nó cũng rất quan trọng để phân biệt giữa request header và response headers. Requests headers là traffic inbound tới các webserver hoặc backend app. Response headers sẽ đi theo cách khác (trong HTTP response bạn có thể nhận lại được bằng các ứng dụng trên clent, ví dụ: curl hoặc browser)

## Redirects and X-Forwarded-Proto

Header này rất quan trọng trong việc ngăn chặn một redirect loop. Khi được sử dụng trong HTTPS server block mỗi HTTP response từ các server được proxy sẽ được viết lại thành HTTPS. Hãy xem ví dụ dưới đây:

1. client gửi HTTP request tới proxy
2. proxy gửi HTTP request tới server 
3. server xem URL là http://
4. server gửi lại 3xx redirect response nói với client để kết nối tới `https://`
5. client gửi một HTTPD request tới proxy
6. Proxy giải mã HTTPS traffic và thiết lập `X-Forwarded-Proto: https`
7. proxy gửi HTTP requests tới server 
8. Server xem URI là `http://` nhưng cũng biết `X-Forwarded-Proto` là https và tin tưởng rằng request là HTTPS
9. Server gửi lại web page hoặc data được request.

Trong bước thứ 6, Proxy được thiết lập HTTP header `X-Forwarded-Proto: https` để chỉ định traffic nó nhận được là HTTPS. Trong bước 8, Server sau khi sử dụng `X-Forwarded-Proto` để xác định nếu request là HTTP hoặc HTTPS.

